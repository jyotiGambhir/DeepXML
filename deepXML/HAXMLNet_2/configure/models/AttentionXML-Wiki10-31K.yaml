name: AttentionXML

model:
  hidden_size: 256
  layers_num: 1
  linear_size: [256]
  dropout: 0.3
  emb_trainable: True

train:
  batch_size: 32
  nb_epoch: 40
  swa_warmup: 5

valid:
  batch_size: 40

predict:
  batch_size: 40

path: models
