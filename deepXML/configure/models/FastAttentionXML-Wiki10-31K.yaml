name: FastAttentionXML

level: 12
k: 8
top: 160

model:
  hidden_size: 512
  layers_num: 1
  linear_size: [512, 256]
  dropout: 0.5

cluster:
  max_leaf: 4
  eps: 1e-4
  levels: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]

train:
  [{batch_size: 200, nb_epoch: 10, swa_warmup: 6},
   {batch_size: 200, nb_epoch: 10, swa_warmup: 2},
   {batch_size: 200, nb_epoch: 10, swa_warmup: 2},
   {batch_size: 200, nb_epoch: 10, swa_warmup: 2}]

valid:
  batch_size: 200

predict:
  batch_size: 200

path: models
